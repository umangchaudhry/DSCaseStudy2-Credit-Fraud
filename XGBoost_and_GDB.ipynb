{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "from datetime import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve, auc, classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "csv_file = \"Data/creditcard.csv\"\n",
    "csv_data = pd.read_csv(csv_file, low_memory = False)\n",
    "Credit_card = pd.DataFrame(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>284315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class\n",
       "Class        \n",
       "0      284315\n",
       "1         492"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Credit_card.groupby('Class')[['Class']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale time and amount\n",
    "\n",
    "# Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "Credit_card['scaled_amount'] = rob_scaler.fit_transform(Credit_card['Amount'].values.reshape(-1,1))\n",
    "Credit_card['scaled_time'] = rob_scaler.fit_transform(Credit_card['Time'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.783274</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.983721</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>-0.994960</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       1.783274    -0.994983 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.269825    -0.994983  1.191857  0.266151  0.166480  0.448154   \n",
       "2       4.983721    -0.994972 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       1.418291    -0.994972 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4       0.670579    -0.994960 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Credit_card.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "scaled_amount = Credit_card['scaled_amount']\n",
    "scaled_time = Credit_card['scaled_time']\n",
    "\n",
    "Credit_card.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "Credit_card.insert(0, 'scaled_amount', scaled_amount)\n",
    "Credit_card.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "# Amount and Time are Scaled!\n",
    "\n",
    "Credit_card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = Credit_card.iloc[:,:-1]\n",
    "Class = Credit_card.iloc[:,-1]\n",
    "## Randomly split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, Class, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56962"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8461538461538461\n",
      "Accuracy rate:  0.9995084442259752\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "f1_sco = f1_score(y_test,y_pred)\n",
    "auc_score = accuracy_score(y_test,y_pred)\n",
    "print(\"F1 score: \", f1_sco)\n",
    "print(\"Accuracy rate: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56862\n",
      "           1       0.94      0.77      0.85       100\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.88      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GDB = GradientBoostingClassifier()\n",
    "model_GDB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.6193548387096774\n",
      "Accuracy rate:  0.9989642217618764\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = model_GDB.predict(X_test)\n",
    "y_pred_proba = model_GDB.predict_proba(X_test)\n",
    "f1_sco = f1_score(y_test,y_pred)\n",
    "auc_score = accuracy_score(y_test,y_pred)\n",
    "print(\"F1 score: \", f1_sco)\n",
    "print(\"Accuracy rate: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56862\n",
      "           1       0.87      0.48      0.62       100\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.94      0.74      0.81     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### see XGB importance feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importancesï¼š [0.01263058 0.01633259 0.02373566 0.01360122 0.02144281 0.0305224\n",
      " 0.01857734 0.01563578 0.02650291 0.0189287  0.01225543 0.05385268\n",
      " 0.01569386 0.02416494 0.019588   0.06004884 0.01895406 0.01719481\n",
      " 0.38603067 0.02419632 0.01306598 0.01592358 0.01893477 0.01130698\n",
      " 0.01467286 0.0152871  0.01373813 0.02444574 0.02947123 0.0132639 ]\n"
     ]
    }
   ],
   "source": [
    "Columns_name = list(X_train.columns)\n",
    "# feature_importances_  \n",
    "importances = clf.feature_importances_\n",
    "print(\"Importancesï¼š\",importances)\n",
    "# Change into dataframe for easier further maniputation \n",
    "Columns_name = pd.DataFrame(Columns_name)\n",
    "importances= pd.DataFrame(importances)\n",
    "# rename\n",
    "Columns_name.rename(columns={0:'Columns name'},inplace = True)\n",
    "importances.rename(columns={0:'importances'},inplace = True)\n",
    "\n",
    "df_import = pd.concat([Columns_name,importances], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns name</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>V17</td>\n",
       "      <td>0.272952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>V12</td>\n",
       "      <td>0.139900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>V14</td>\n",
       "      <td>0.139553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>V10</td>\n",
       "      <td>0.089139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>V7</td>\n",
       "      <td>0.073872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>V20</td>\n",
       "      <td>0.055923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>V4</td>\n",
       "      <td>0.052469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>V3</td>\n",
       "      <td>0.045629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>V26</td>\n",
       "      <td>0.042645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>V28</td>\n",
       "      <td>0.035655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Columns name  importances\n",
       "18          V17     0.272952\n",
       "13          V12     0.139900\n",
       "15          V14     0.139553\n",
       "11          V10     0.089139\n",
       "8            V7     0.073872\n",
       "21          V20     0.055923\n",
       "5            V4     0.052469\n",
       "4            V3     0.045629\n",
       "27          V26     0.042645\n",
       "29          V28     0.035655"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Order the important from higher values to smaller values\n",
    "df_import = df_import.sort_values(by ='importances',ascending = False)\n",
    "df_import.iloc[0:10,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random UnderSampling technique\n",
    "### avoid imbalance data and hope increasing the accracy in fraud case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Label Distributions: \n",
      "\n",
      "[0.99827953 0.00172047]\n",
      "[0.99824444 0.00175556]\n"
     ]
    }
   ],
   "source": [
    "# See if both the train and test label distribution are similarly distributed\n",
    "train_unique_label, train_counts_label = np.unique(y_train, return_counts=True)\n",
    "test_unique_label, test_counts_label = np.unique(y_test, return_counts=True)\n",
    "print('-' * 100)\n",
    "\n",
    "print('Label Distributions: \\n')\n",
    "print(train_counts_label/ len(y_train))\n",
    "print(test_counts_label/ len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>245363</td>\n",
       "      <td>1.170684</td>\n",
       "      <td>0.799199</td>\n",
       "      <td>1.790930</td>\n",
       "      <td>-0.240430</td>\n",
       "      <td>-1.675534</td>\n",
       "      <td>1.389349</td>\n",
       "      <td>0.207745</td>\n",
       "      <td>-0.875449</td>\n",
       "      <td>0.566065</td>\n",
       "      <td>-0.214348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195768</td>\n",
       "      <td>0.148093</td>\n",
       "      <td>0.322911</td>\n",
       "      <td>-0.070732</td>\n",
       "      <td>-0.014347</td>\n",
       "      <td>0.328102</td>\n",
       "      <td>-0.517286</td>\n",
       "      <td>-0.046950</td>\n",
       "      <td>-0.057782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201601</td>\n",
       "      <td>1.512052</td>\n",
       "      <td>0.578790</td>\n",
       "      <td>0.523820</td>\n",
       "      <td>1.531708</td>\n",
       "      <td>-4.176390</td>\n",
       "      <td>3.584615</td>\n",
       "      <td>-1.023954</td>\n",
       "      <td>-0.502471</td>\n",
       "      <td>-1.891966</td>\n",
       "      <td>0.878417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621804</td>\n",
       "      <td>0.851859</td>\n",
       "      <td>1.176927</td>\n",
       "      <td>0.453553</td>\n",
       "      <td>0.485211</td>\n",
       "      <td>-0.500687</td>\n",
       "      <td>-0.108284</td>\n",
       "      <td>0.269477</td>\n",
       "      <td>-0.063245</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117092</td>\n",
       "      <td>-0.279746</td>\n",
       "      <td>-0.119339</td>\n",
       "      <td>1.255641</td>\n",
       "      <td>0.327694</td>\n",
       "      <td>0.298430</td>\n",
       "      <td>0.697195</td>\n",
       "      <td>-0.404281</td>\n",
       "      <td>-1.081899</td>\n",
       "      <td>0.062537</td>\n",
       "      <td>-0.183395</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103499</td>\n",
       "      <td>-0.291627</td>\n",
       "      <td>-0.859557</td>\n",
       "      <td>0.133538</td>\n",
       "      <td>0.335495</td>\n",
       "      <td>0.203784</td>\n",
       "      <td>0.095592</td>\n",
       "      <td>-0.025470</td>\n",
       "      <td>0.030083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251866</td>\n",
       "      <td>-0.252917</td>\n",
       "      <td>0.832282</td>\n",
       "      <td>0.711155</td>\n",
       "      <td>2.617105</td>\n",
       "      <td>-4.722363</td>\n",
       "      <td>5.842970</td>\n",
       "      <td>-0.600179</td>\n",
       "      <td>-1.646313</td>\n",
       "      <td>-2.785198</td>\n",
       "      <td>0.540368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461032</td>\n",
       "      <td>0.360501</td>\n",
       "      <td>-0.865526</td>\n",
       "      <td>0.139978</td>\n",
       "      <td>-0.336238</td>\n",
       "      <td>0.128449</td>\n",
       "      <td>-0.155646</td>\n",
       "      <td>0.799460</td>\n",
       "      <td>0.392170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8842</td>\n",
       "      <td>-0.307413</td>\n",
       "      <td>-0.852912</td>\n",
       "      <td>-4.696795</td>\n",
       "      <td>2.693867</td>\n",
       "      <td>-4.475133</td>\n",
       "      <td>5.467685</td>\n",
       "      <td>-1.556758</td>\n",
       "      <td>-1.549420</td>\n",
       "      <td>-4.104215</td>\n",
       "      <td>0.553934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158971</td>\n",
       "      <td>0.573898</td>\n",
       "      <td>-0.080163</td>\n",
       "      <td>0.318408</td>\n",
       "      <td>-0.245862</td>\n",
       "      <td>0.338238</td>\n",
       "      <td>0.032271</td>\n",
       "      <td>-1.508458</td>\n",
       "      <td>0.608075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "245363       1.170684     0.799199  1.790930 -0.240430 -1.675534  1.389349   \n",
       "201601       1.512052     0.578790  0.523820  1.531708 -4.176390  3.584615   \n",
       "117092      -0.279746    -0.119339  1.255641  0.327694  0.298430  0.697195   \n",
       "251866      -0.252917     0.832282  0.711155  2.617105 -4.722363  5.842970   \n",
       "8842        -0.307413    -0.852912 -4.696795  2.693867 -4.475133  5.467685   \n",
       "\n",
       "              V5        V6        V7        V8  ...       V20       V21  \\\n",
       "245363  0.207745 -0.875449  0.566065 -0.214348  ... -0.195768  0.148093   \n",
       "201601 -1.023954 -0.502471 -1.891966  0.878417  ...  0.621804  0.851859   \n",
       "117092 -0.404281 -1.081899  0.062537 -0.183395  ... -0.103499 -0.291627   \n",
       "251866 -0.600179 -1.646313 -2.785198  0.540368  ...  0.461032  0.360501   \n",
       "8842   -1.556758 -1.549420 -4.104215  0.553934  ... -0.158971  0.573898   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "245363  0.322911 -0.070732 -0.014347  0.328102 -0.517286 -0.046950 -0.057782   \n",
       "201601  1.176927  0.453553  0.485211 -0.500687 -0.108284  0.269477 -0.063245   \n",
       "117092 -0.859557  0.133538  0.335495  0.203784  0.095592 -0.025470  0.030083   \n",
       "251866 -0.865526  0.139978 -0.336238  0.128449 -0.155646  0.799460  0.392170   \n",
       "8842   -0.080163  0.318408 -0.245862  0.338238  0.032271 -1.508458  0.608075   \n",
       "\n",
       "        Class  \n",
       "245363      0  \n",
       "201601      1  \n",
       "117092      0  \n",
       "251866      1  \n",
       "8842        1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Credit_card = Credit_card.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_df = Credit_card.loc[Credit_card['Class'] == 1]\n",
    "non_fraud_df = Credit_card.loc[Credit_card['Class'] == 0][:492]\n",
    "\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the Classes in the subsample dataset\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: Class, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Distribution of the Classes in the subsample dataset')\n",
    "print(new_df['Class'].value_counts()/len(new_df))\n",
    "\n",
    "sns.countplot('Class', data=new_df)\n",
    "plt.title('Equally Distributed Classes', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use new dataset and train XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = new_df.iloc[:,:-1]\n",
    "y_train_new = new_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_new = XGBClassifier()\n",
    "clf_new.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.08635578583765113\n",
      "Accuracy rate:  0.9628524279344124\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = clf_new.predict(X_test)\n",
    "y_pred_proba = clf_new.predict_proba(X_test)\n",
    "f1_sco = f1_score(y_test,y_pred)\n",
    "auc_score = accuracy_score(y_test,y_pred)\n",
    "fpr_1,tpr_1,threshold = roc_curve(y_test, y_pred_proba[:,1]) ### FPR TPR\n",
    "roc_auc_1 = auc(fpr_1,tpr_1)\n",
    "print(\"F1 score: \", f1_sco)\n",
    "print(\"Accuracy rate: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     56862\n",
      "           1       0.05      1.00      0.09       100\n",
      "\n",
      "    accuracy                           0.96     56962\n",
      "   macro avg       0.52      0.98      0.53     56962\n",
      "weighted avg       1.00      0.96      0.98     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: Cannot get a good result by using RUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random overSampling technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(df_x, Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>284315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>284315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class\n",
       "Class        \n",
       "0      284315\n",
       "1      284315"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1.groupby('Class')[['Class']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.999666964645668\n",
      "Accuracy rate:  0.9996658635668185\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "f1_sco = f1_score(y_test,y_pred)\n",
    "auc_score = accuracy_score(y_test,y_pred)\n",
    "print(\"F1 score: \", f1_sco)\n",
    "print(\"Accuracy rate: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   1.000000  0.999330  0.999665     56694\n",
      "           1   0.999334  1.000000  0.999667     57032\n",
      "\n",
      "    accuracy                       0.999666    113726\n",
      "   macro avg   0.999667  0.999665  0.999666    113726\n",
      "weighted avg   0.999666  0.999666  0.999666    113726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred,digits=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: the result shows that after using ROC, our model performance looks great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn parameter based on cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the initial parameter\n",
    "model = XGBClassifier(learning_rate=0.300000012,\n",
    "                      n_estimators=100,           \n",
    "                      max_depth=6,               \n",
    "                      min_child_weight = 1,      \n",
    "                      gamma=0.,                  \n",
    "                      subsample= 1,                   \n",
    "                      scale_pos_weight=1,        \n",
    "                      random_state=0,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=0.0,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.300000012,\n",
       "                                     max_delta_step=None, max_depth=6,\n",
       "                                     min_child_weight=1, missing=nan,\n",
       "                                     monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=0,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=1, subsample=1,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'learning_rate': [0.1, 0.2, 0.300000012],\n",
       "                         'max_depth': [5, 6, 7], 'n_estimators': [100, 200]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test = {\n",
    "    'n_estimators': list(range(100, 300,100)),\n",
    "    'max_depth': list(range(5, 8, 1)),\n",
    "    'learning_rate':  [0.1,0.2,0.300000012]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator = model, param_grid = param_test, \n",
    "scoring='accuracy', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "? warning: if you want to run the code chunk below. You should run about 2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'mean_fit_time': array([ 41.53203907,  89.56298556,  48.91545844,  87.71751547,\n",
       "          50.78208756, 101.66982293,  37.0730566 ,  70.72200685,\n",
       "          43.20697765,  79.13098245,  47.95204   ,  89.08022237,\n",
       "          34.14792237,  66.0519372 ,  40.33389707,  74.13720574,\n",
       "          45.15862498,  82.62068501]),\n",
       "  'std_fit_time': array([ 1.2152014 , 10.43434933,  5.3316885 ,  2.47876532,  2.21768201,\n",
       "          3.7613283 ,  3.21737596,  5.59384889,  2.00858052,  0.50610887,\n",
       "          0.56939002,  1.31210661,  0.31774497,  0.4369143 ,  0.63402898,\n",
       "          1.26438456,  0.36187056,  1.99139073]),\n",
       "  'mean_score_time': array([0.19448767, 0.29588227, 0.18104491, 0.28310313, 0.17785764,\n",
       "         0.31260161, 0.16355901, 0.24713173, 0.17718859, 0.25891294,\n",
       "         0.19072585, 0.28387289, 0.16009808, 0.23981962, 0.16760445,\n",
       "         0.24911146, 0.18172922, 0.28073945]),\n",
       "  'std_score_time': array([0.01993381, 0.02081845, 0.01386962, 0.02705434, 0.00358533,\n",
       "         0.02052486, 0.00867536, 0.01880941, 0.00394175, 0.00728482,\n",
       "         0.00263432, 0.00566382, 0.00306394, 0.01363191, 0.00946696,\n",
       "         0.0029593 , 0.00617136, 0.00971437]),\n",
       "  'param_learning_rate': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                     0.2, 0.300000012, 0.300000012, 0.300000012,\n",
       "                     0.300000012, 0.300000012, 0.300000012],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_max_depth': masked_array(data=[5, 5, 6, 6, 7, 7, 5, 5, 6, 6, 7, 7, 5, 5, 6, 6, 7, 7],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'param_n_estimators': masked_array(data=[100, 200, 100, 200, 100, 200, 100, 200, 100, 200, 100,\n",
       "                     200, 100, 200, 100, 200, 100, 200],\n",
       "               mask=[False, False, False, False, False, False, False, False,\n",
       "                     False, False, False, False, False, False, False, False,\n",
       "                     False, False],\n",
       "         fill_value='?',\n",
       "              dtype=object),\n",
       "  'params': [{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100},\n",
       "   {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200},\n",
       "   {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 100},\n",
       "   {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200},\n",
       "   {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 100},\n",
       "   {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200},\n",
       "   {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100},\n",
       "   {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200},\n",
       "   {'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 100},\n",
       "   {'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 200},\n",
       "   {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100},\n",
       "   {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200},\n",
       "   {'learning_rate': 0.300000012, 'max_depth': 5, 'n_estimators': 100},\n",
       "   {'learning_rate': 0.300000012, 'max_depth': 5, 'n_estimators': 200},\n",
       "   {'learning_rate': 0.300000012, 'max_depth': 6, 'n_estimators': 100},\n",
       "   {'learning_rate': 0.300000012, 'max_depth': 6, 'n_estimators': 200},\n",
       "   {'learning_rate': 0.300000012, 'max_depth': 7, 'n_estimators': 100},\n",
       "   {'learning_rate': 0.300000012, 'max_depth': 7, 'n_estimators': 200}],\n",
       "  'split0_test_score': array([0.99527374, 0.99916466, 0.99730713, 0.99956035, 0.99875798,\n",
       "         0.99975819, 0.99893384, 0.9997472 , 0.99958233, 0.99976918,\n",
       "         0.99970323, 0.99983513, 0.99957134, 0.99982414, 0.99976918,\n",
       "         0.99983513, 0.99978017, 0.99985711]),\n",
       "  'split1_test_score': array([0.99448236, 0.99892285, 0.99755993, 0.99954936, 0.99865906,\n",
       "         0.99967026, 0.99893384, 0.9996153 , 0.99946143, 0.99972522,\n",
       "         0.9996263 , 0.99978017, 0.9994944 , 0.99969224, 0.99967026,\n",
       "         0.9997472 , 0.99972522, 0.99980216]),\n",
       "  'split2_test_score': array([0.99520779, 0.99894483, 0.99751596, 0.99954936, 0.99872501,\n",
       "         0.9997472 , 0.99921962, 0.99972522, 0.99959332, 0.99973621,\n",
       "         0.99963729, 0.99976918, 0.9994944 , 0.99967026, 0.99975819,\n",
       "         0.99976918, 0.99972522, 0.99973621]),\n",
       "  'split3_test_score': array([0.99535068, 0.99929656, 0.99798859, 0.99965927, 0.998736  ,\n",
       "         0.9997472 , 0.99927457, 0.99978017, 0.99957134, 0.99976918,\n",
       "         0.99976918, 0.99982414, 0.9996263 , 0.99975819, 0.99975819,\n",
       "         0.99981315, 0.99976918, 0.99981315]),\n",
       "  'split4_test_score': array([0.99527369, 0.99910969, 0.99739503, 0.99941745, 0.99877995,\n",
       "         0.99964827, 0.99906573, 0.99967026, 0.99945043, 0.99972521,\n",
       "         0.99965927, 0.99980215, 0.99954935, 0.99976918, 0.99963728,\n",
       "         0.9997472 , 0.99972521, 0.99978017]),\n",
       "  'mean_test_score': array([0.99511765, 0.99908772, 0.99755333, 0.99954716, 0.9987316 ,\n",
       "         0.99971423, 0.99908552, 0.99970763, 0.99953177, 0.999745  ,\n",
       "         0.99967905, 0.99980216, 0.99954716, 0.9997428 , 0.99971862,\n",
       "         0.99978237, 0.999745  , 0.99979776]),\n",
       "  'std_test_score': array([3.20850726e-04, 1.39723358e-04, 2.35186981e-04, 7.69098906e-05,\n",
       "         4.08868497e-05, 4.55852325e-05, 1.41510949e-04, 5.84097152e-05,\n",
       "         6.24105151e-05, 2.01479897e-05, 5.22060943e-05, 2.50640337e-05,\n",
       "         4.98379843e-05, 5.54377960e-05, 5.41159416e-05, 3.57180637e-05,\n",
       "         2.44792887e-05, 3.96908530e-05]),\n",
       "  'rank_test_score': array([18, 14, 17, 12, 16,  8, 15,  9, 13,  4, 10,  1, 11,  6,  7,  3,  4,\n",
       "          2], dtype=int32)},\n",
       " {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 200},\n",
       " 0.9998021560592966)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_, grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.2, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = XGBClassifier(learning_rate=0.2,\n",
    "                      n_estimators=200,           \n",
    "                      max_depth= 7,               \n",
    "                      min_child_weight = 1,      \n",
    "                      gamma=0.,                  \n",
    "                      subsample= 1,                   \n",
    "                      scale_pos_weight=1,        \n",
    "                      random_state=0,         \n",
    "                      )\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.9997545840199138\n",
      "Accuracy rate:  0.9997537942071294\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "f1_sco = f1_score(y_test,y_pred)\n",
    "auc_score = accuracy_score(y_test,y_pred)\n",
    "print(\"F1 score: \", f1_sco)\n",
    "print(\"Accuracy rate: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   1.000000  0.999506  0.999753     56694\n",
      "           1   0.999509  1.000000  0.999755     57032\n",
      "\n",
      "    accuracy                       0.999754    113726\n",
      "   macro avg   0.999755  0.999753  0.999754    113726\n",
      "weighted avg   0.999754  0.999754  0.999754    113726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred,digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importancesï¼š [0.01476339 0.01096184 0.01289754 0.00882999 0.01310493 0.05381585\n",
      " 0.01139669 0.00571928 0.00970536 0.03096063 0.01255684 0.01538373\n",
      " 0.01069947 0.02413362 0.01575773 0.632163   0.00682736 0.00570555\n",
      " 0.01272748 0.00960132 0.00979784 0.00681195 0.00927369 0.00986594\n",
      " 0.01175314 0.00378064 0.0073787  0.00760545 0.00774468 0.00827656]\n"
     ]
    }
   ],
   "source": [
    "Columns_name = list(X_train.columns)\n",
    "# feature_importances_  \n",
    "importances = clf.feature_importances_\n",
    "print(\"Importancesï¼š\",importances)\n",
    "# Change into dataframe for easier further maniputation \n",
    "Columns_name = pd.DataFrame(Columns_name)\n",
    "importances= pd.DataFrame(importances)\n",
    "# rename\n",
    "Columns_name.rename(columns={0:'Columns name'},inplace = True)\n",
    "importances.rename(columns={0:'importances'},inplace = True)\n",
    "\n",
    "df_import = pd.concat([Columns_name,importances], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns name</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>V14</td>\n",
       "      <td>0.632163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>V4</td>\n",
       "      <td>0.053816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>V8</td>\n",
       "      <td>0.030961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>V12</td>\n",
       "      <td>0.024134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>V13</td>\n",
       "      <td>0.015758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>V10</td>\n",
       "      <td>0.015384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>scaled_amount</td>\n",
       "      <td>0.014763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>V3</td>\n",
       "      <td>0.013105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>V1</td>\n",
       "      <td>0.012898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>V17</td>\n",
       "      <td>0.012727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Columns name  importances\n",
       "15            V14     0.632163\n",
       "5              V4     0.053816\n",
       "9              V8     0.030961\n",
       "13            V12     0.024134\n",
       "14            V13     0.015758\n",
       "11            V10     0.015384\n",
       "0   scaled_amount     0.014763\n",
       "4              V3     0.013105\n",
       "2              V1     0.012898\n",
       "18            V17     0.012727"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Order the important from higher values to smaller values\n",
    "df_import = df_import.sort_values(by ='importances',ascending = False)\n",
    "df_import.iloc[0:10,]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
