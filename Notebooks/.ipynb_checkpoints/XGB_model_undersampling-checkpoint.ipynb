{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/usr/local/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /usr/local/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c241ca330b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/xgboost/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeviceQuantileDMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrabit\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;31m# load the XGBoost library globally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlib_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mlibname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         raise XGBoostError(\n\u001b[0m\u001b[1;32m    157\u001b[0m             \u001b[0;34m'XGBoost Library ({}) could not be loaded.\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;34m'Likely causes:\\n'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: XGBoost Library (libxgboost.dylib) could not be loaded.\nLikely causes:\n  * OpenMP runtime is not installed (vcomp140.dll or libgomp-1.dll for Windows, libomp.dylib for Mac OSX, libgomp.so for Linux and other UNIX-like OSes). Mac OSX users: Run `brew install libomp` to install OpenMP runtime.\n  * You are running 32-bit Python on a 64-bit OS\nError message(s): ['dlopen(/usr/local/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\\n  Referenced from: /usr/local/lib/python3.8/site-packages/xgboost/lib/libxgboost.dylib\\n  Reason: image not found']\n"
     ]
    }
   ],
   "source": [
    "# load library\n",
    "from datetime import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_curve, auc, classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,recall_score,precision_recall_curve,auc,roc_curve,roc_auc_score,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "csv_file = \"Data/creditcard.csv\"\n",
    "csv_data = pd.read_csv(csv_file, low_memory = False)\n",
    "Credit_card = pd.DataFrame(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale time and amount\n",
    "\n",
    "# Since most of our data has already been scaled we should scale the columns that are left to scale (Amount and Time)\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "Credit_card['scaled_amount'] = rob_scaler.fit_transform(Credit_card['Amount'].values.reshape(-1,1))\n",
    "Credit_card['scaled_time'] = rob_scaler.fit_transform(Credit_card['Time'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.783274</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.983721</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>-0.994960</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       1.783274    -0.994983 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.269825    -0.994983  1.191857  0.266151  0.166480  0.448154   \n",
       "2       4.983721    -0.994972 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       1.418291    -0.994972 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4       0.670579    -0.994960 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Credit_card.drop(['Time','Amount'], axis=1, inplace=True)\n",
    "scaled_amount = Credit_card['scaled_amount']\n",
    "scaled_time = Credit_card['scaled_time']\n",
    "\n",
    "Credit_card.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "Credit_card.insert(0, 'scaled_amount', scaled_amount)\n",
    "Credit_card.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "# Amount and Time are Scaled!\n",
    "\n",
    "Credit_card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = Credit_card.iloc[:,:-1]\n",
    "Class = Credit_card.iloc[:,-1]\n",
    "## Randomly split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_x, Class, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Label Distributions: \n",
      "\n",
      "[0.99827953 0.00172047]\n",
      "[0.99824444 0.00175556]\n"
     ]
    }
   ],
   "source": [
    "# See if both the train and test label distribution are similarly distributed\n",
    "train_unique_label, train_counts_label = np.unique(y_train, return_counts=True)\n",
    "test_unique_label, test_counts_label = np.unique(y_test, return_counts=True)\n",
    "print('-' * 100)\n",
    "\n",
    "print('Label Distributions: \\n')\n",
    "print(train_counts_label/ len(y_train))\n",
    "print(test_counts_label/ len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29260</td>\n",
       "      <td>1.900370</td>\n",
       "      <td>-0.579295</td>\n",
       "      <td>-0.793702</td>\n",
       "      <td>-0.637689</td>\n",
       "      <td>0.850220</td>\n",
       "      <td>-0.610884</td>\n",
       "      <td>1.614707</td>\n",
       "      <td>4.444885</td>\n",
       "      <td>0.181640</td>\n",
       "      <td>0.486776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095484</td>\n",
       "      <td>-0.360763</td>\n",
       "      <td>-0.109101</td>\n",
       "      <td>0.050993</td>\n",
       "      <td>0.990356</td>\n",
       "      <td>0.528149</td>\n",
       "      <td>-0.077599</td>\n",
       "      <td>-0.203811</td>\n",
       "      <td>-0.430370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147548</td>\n",
       "      <td>-0.290924</td>\n",
       "      <td>0.046758</td>\n",
       "      <td>-3.859881</td>\n",
       "      <td>2.632881</td>\n",
       "      <td>-5.264265</td>\n",
       "      <td>3.446113</td>\n",
       "      <td>-0.675231</td>\n",
       "      <td>-1.904959</td>\n",
       "      <td>-3.291041</td>\n",
       "      <td>-0.985766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178626</td>\n",
       "      <td>1.664119</td>\n",
       "      <td>0.785075</td>\n",
       "      <td>0.068412</td>\n",
       "      <td>0.778961</td>\n",
       "      <td>-0.863166</td>\n",
       "      <td>-0.006810</td>\n",
       "      <td>-1.065734</td>\n",
       "      <td>1.773326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196445</td>\n",
       "      <td>-0.293440</td>\n",
       "      <td>0.550053</td>\n",
       "      <td>-0.974966</td>\n",
       "      <td>1.110190</td>\n",
       "      <td>0.193460</td>\n",
       "      <td>-2.635929</td>\n",
       "      <td>0.670230</td>\n",
       "      <td>-0.759960</td>\n",
       "      <td>0.860737</td>\n",
       "      <td>0.380987</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116771</td>\n",
       "      <td>-0.173387</td>\n",
       "      <td>-0.593201</td>\n",
       "      <td>-0.052232</td>\n",
       "      <td>0.737148</td>\n",
       "      <td>-0.065977</td>\n",
       "      <td>0.320069</td>\n",
       "      <td>0.102952</td>\n",
       "      <td>0.100057</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43773</td>\n",
       "      <td>2.100468</td>\n",
       "      <td>-0.505716</td>\n",
       "      <td>-3.240187</td>\n",
       "      <td>2.978122</td>\n",
       "      <td>-4.162314</td>\n",
       "      <td>3.869124</td>\n",
       "      <td>-3.645256</td>\n",
       "      <td>-0.126271</td>\n",
       "      <td>-4.744730</td>\n",
       "      <td>-0.065331</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224043</td>\n",
       "      <td>2.601441</td>\n",
       "      <td>0.231910</td>\n",
       "      <td>-0.036490</td>\n",
       "      <td>0.042640</td>\n",
       "      <td>-0.438330</td>\n",
       "      <td>-0.125821</td>\n",
       "      <td>0.421300</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43681</td>\n",
       "      <td>0.446447</td>\n",
       "      <td>-0.506174</td>\n",
       "      <td>-18.247513</td>\n",
       "      <td>8.713250</td>\n",
       "      <td>-17.880127</td>\n",
       "      <td>9.249459</td>\n",
       "      <td>-14.541213</td>\n",
       "      <td>-1.911564</td>\n",
       "      <td>-18.014660</td>\n",
       "      <td>5.522162</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.526368</td>\n",
       "      <td>0.598843</td>\n",
       "      <td>0.615319</td>\n",
       "      <td>-0.486499</td>\n",
       "      <td>0.739268</td>\n",
       "      <td>-0.236845</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>-3.011473</td>\n",
       "      <td>-1.022147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        scaled_amount  scaled_time         V1        V2         V3        V4  \\\n",
       "29260        1.900370    -0.579295  -0.793702 -0.637689   0.850220 -0.610884   \n",
       "147548      -0.290924     0.046758  -3.859881  2.632881  -5.264265  3.446113   \n",
       "196445      -0.293440     0.550053  -0.974966  1.110190   0.193460 -2.635929   \n",
       "43773        2.100468    -0.505716  -3.240187  2.978122  -4.162314  3.869124   \n",
       "43681        0.446447    -0.506174 -18.247513  8.713250 -17.880127  9.249459   \n",
       "\n",
       "               V5        V6         V7        V8  ...       V20       V21  \\\n",
       "29260    1.614707  4.444885   0.181640  0.486776  ... -0.095484 -0.360763   \n",
       "147548  -0.675231 -1.904959  -3.291041 -0.985766  ... -0.178626  1.664119   \n",
       "196445   0.670230 -0.759960   0.860737  0.380987  ... -0.116771 -0.173387   \n",
       "43773   -3.645256 -0.126271  -4.744730 -0.065331  ... -0.224043  2.601441   \n",
       "43681  -14.541213 -1.911564 -18.014660  5.522162  ... -0.526368  0.598843   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "29260  -0.109101  0.050993  0.990356  0.528149 -0.077599 -0.203811 -0.430370   \n",
       "147548  0.785075  0.068412  0.778961 -0.863166 -0.006810 -1.065734  1.773326   \n",
       "196445 -0.593201 -0.052232  0.737148 -0.065977  0.320069  0.102952  0.100057   \n",
       "43773   0.231910 -0.036490  0.042640 -0.438330 -0.125821  0.421300  0.003146   \n",
       "43681   0.615319 -0.486499  0.739268 -0.236845 -0.046082 -3.011473 -1.022147   \n",
       "\n",
       "        Class  \n",
       "29260       0  \n",
       "147548      1  \n",
       "196445      0  \n",
       "43773       1  \n",
       "43681       1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Credit_card = Credit_card.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_df = Credit_card.loc[Credit_card['Class'] == 1]\n",
    "non_fraud_df = Credit_card.loc[Credit_card['Class'] == 0][:492]\n",
    "\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of the Classes in the subsample dataset\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: Class, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Distribution of the Classes in the subsample dataset')\n",
    "print(new_df['Class'].value_counts()/len(new_df))\n",
    "\n",
    "sns.countplot('Class', data=new_df)\n",
    "plt.title('Equally Distributed Classes', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new = new_df.iloc[:,:-1]\n",
    "y_train_new = new_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_new = XGBClassifier()\n",
    "clf_new.fit(X_train_new, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.102880658436214\n",
      "Accuracy rate:  0.9693830975035989\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = clf_new.predict(X_test)\n",
    "y_pred_proba = clf_new.predict_proba(X_test)\n",
    "f1_sco = f1_score(y_test,y_pred)\n",
    "auc_score = accuracy_score(y_test,y_pred)\n",
    "print(\"F1 score: \", f1_sco)\n",
    "print(\"Accuracy rate: \", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first make a model function for modeling with confusion matrix\n",
    "def model(model,features_train,features_test,labels_train,labels_test):\n",
    "    clf= model\n",
    "    clf.fit(features_train,labels_train.values.ravel())\n",
    "    pred=clf.predict(features_test)\n",
    "    pred_prob = clf.predict_proba(features_test)\n",
    "    accuracy = accuracy_score(labels_test, pred)\n",
    "    cnf_matrix=confusion_matrix(labels_test,pred)\n",
    "\n",
    "    fig= plt.figure(figsize=(6,3))# to plot the graph\n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "    \n",
    "    \n",
    "    print(\"TPR for the two class\", TPR)\n",
    "    print(\"TNR for the two class\", TNR)\n",
    "    print(\"FPR for the two class\", FPR)\n",
    "    print(\"FNR for the two class\", FNR)\n",
    "    print(\"TP\",cnf_matrix[1,1,]) # no of fraud transaction which are predicted fraud\n",
    "    print(\"TN\",cnf_matrix[0,0]) # no. of normal transaction which are predited normal\n",
    "    print(\"FP\",cnf_matrix[0,1]) # no of normal transaction which are predicted fraud\n",
    "    print(\"FN\",cnf_matrix[1,0]) # no of fraud Transaction which are predicted normal\n",
    "    sns.heatmap(cnf_matrix,cmap=\"coolwarm_r\",annot=True,linewidths=0.5)\n",
    "    plt.title(\"Confusion_matrix\")\n",
    "    plt.xlabel(\"Predicted_class\")\n",
    "    plt.ylabel(\"Real class\")\n",
    "    plt.show()\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Confusion matrix:\",cnf_matrix)\n",
    "    \n",
    "    print(\"\\n----------Classification Report------------------------------------\")\n",
    "    print(classification_report(labels_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TPR for the two class [0.96932925 1.        ]\n",
      "TNR for the two class [1.         0.96932925]\n",
      "FPR for the two class [0.         0.03067075]\n",
      "FNR for the two class [0.03067075 0.        ]\n",
      "TP 100\n",
      "TN 55118\n",
      "FP 1744\n",
      "FN 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9693830975035989\n",
      "Confusion matrix: [[55118  1744]\n",
      " [    0   100]]\n",
      "\n",
      "----------Classification Report------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     56862\n",
      "           1       0.05      1.00      0.10       100\n",
      "\n",
      "    accuracy                           0.97     56962\n",
      "   macro avg       0.53      0.98      0.54     56962\n",
      "weighted avg       1.00      0.97      0.98     56962\n",
      "\n",
      "_________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#the partion for whole data\n",
    "print()\n",
    "model(XGBClassifier(),X_train_new, X_test, y_train_new, y_test)\n",
    "# here training for the undersample data but tatsing for whole data\n",
    "print(\"_________________________________________________________________________________________\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
